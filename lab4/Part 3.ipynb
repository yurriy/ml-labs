{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipdb\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def board_to_int(board):\n",
    "    x = 0\n",
    "    for i in range(9):\n",
    "        x *= 3\n",
    "        x += board.flat[8 - i]\n",
    "    return x\n",
    "\n",
    "def int_to_board(x):\n",
    "    board = np.zeros((3, 3), 'int')\n",
    "    for i in range(9):\n",
    "        board.flat[i] = x % 3\n",
    "        x //= 3\n",
    "    return board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_coding_encoding(tests_cnt):\n",
    "    for i in range(tests_cnt):\n",
    "        d = np.random.randint(3, size=(3, 3))\n",
    "        x = board_to_int(d)\n",
    "        d2 = int_to_board(x)\n",
    "        if not ((d2 == d).all()):\n",
    "            print('err')\n",
    "            return\n",
    "\n",
    "test_coding_encoding(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_allowed_actions(state):\n",
    "    board = int_to_board(state)\n",
    "    return np.flatnonzero(board == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states_count = 3 ** 9\n",
    "allowed_actions = list(map(calc_allowed_actions, range(states_count)))\n",
    "base_states = np.repeat(-1, states_count)\n",
    "transforms = np.empty(states_count, dtype=tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_similar_states(base_state):\n",
    "    board = int_to_board(base_state)\n",
    "    for i in range(4):\n",
    "        state = board_to_int(board)\n",
    "        base_states[state] = base_state\n",
    "        transforms[state] = np.array((i, 0))\n",
    "        board_reversed = np.fliplr(board)\n",
    "        reversed_state = board_to_int(board_reversed)\n",
    "        transforms[reversed_state] = np.array((i, 1))\n",
    "        base_states[reversed_state] = base_state\n",
    "        board = np.rot90(board)\n",
    "        \n",
    "        \n",
    "for state in range(states_count):\n",
    "    if base_states[state] == -1:\n",
    "        find_similar_states(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Judge:\n",
    "    def __init__(self):\n",
    "        self.DRAW = 0\n",
    "        self.PLAYING = 3\n",
    "        self.results = list(map(self.calc_game_status, range(states_count)))\n",
    "\n",
    "    def get_board_lines(self, state):\n",
    "        board = int_to_board(state)\n",
    "        board_rotated = np.rot90(board)\n",
    "        diag1 = np.diag(board)\n",
    "        diag2 = np.diag(board_rotated)\n",
    "        return np.vstack([board, board_rotated, diag1, diag2])\n",
    "        \n",
    "    def line_winner(self, line):\n",
    "        for player in range(1, 3):\n",
    "            if (line == player).all():\n",
    "                return player\n",
    "        return 0\n",
    "\n",
    "    def calc_game_status(self, state):\n",
    "        all_lines = self.get_board_lines(state)\n",
    "        for line in all_lines:\n",
    "            if self.line_winner(line):\n",
    "                return self.line_winner(line)\n",
    "        return self.PLAYING if len(allowed_actions[state]) else self.DRAW\n",
    "    \n",
    "    def get_result(self, state):\n",
    "        return self.results[state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "judge = Judge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AgentSARSA:\n",
    "    def __init__(self, epsilon=0.01, gamma=0.5, alpha=0.1):\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        #self.alpha = alpha\n",
    "        self.q = np.zeros((states_count, 9))\n",
    "        self.count = np.zeros((states_count, 9), 'int')\n",
    "        self.prev_state = 0\n",
    "        self.prev_action = 0\n",
    "        \n",
    "    def choose_action(self, state):\n",
    "        q = self.q[state].take(allowed_actions[state])\n",
    "        indices_of_best = np.flatnonzero(q == q.max())\n",
    "        best_actions = allowed_actions[state].take(indices_of_best)\n",
    "        good_choice = np.random.choice(best_actions)\n",
    "        rand_choice = np.random.choice(allowed_actions[state])\n",
    "        return np.random.choice([good_choice, rand_choice], p=[1 - self.epsilon, self.epsilon])\n",
    "    \n",
    "    def alpha(self, cnt):\n",
    "        return 0.1\n",
    "        return np.log(cnt + 1) ** -1\n",
    "        \n",
    "    def get_action(self, state):\n",
    "        action = self.choose_action(state)\n",
    "        self.count[state][action] += 1\n",
    "        alpha = self.alpha(self.count[self.prev_state][self.prev_action] + 1)\n",
    "        if state != -1:\n",
    "            self.q[self.prev_state][self.prev_action] += alpha * (self.gamma * self.q[state][action]\n",
    "                                                                  - self.q[self.prev_state][self.prev_action])\n",
    "        self.prev_state = state\n",
    "        self.prev_action = action\n",
    "        return action\n",
    "    \n",
    "    def put_reward(self, reward):\n",
    "        alpha = self.alpha(self.count[self.prev_state][self.prev_action] + 1)\n",
    "        self.q[self.prev_state][self.prev_action] += alpha * (reward\n",
    "                                                              - self.q[self.prev_state][self.prev_action])\n",
    "        self.state = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Simulator:\n",
    "    def __init__(self, judge, agents):\n",
    "        self.agents = agents\n",
    "        self.judge = judge\n",
    "        \n",
    "    def play_games(self, games_cnt):\n",
    "        for i in range(games_cnt):\n",
    "            if i % 100 == 0 or i == games_cnt - 1:\n",
    "                progress = round((i + 1) / games_cnt * 100, 1)\n",
    "                print('\\r' * 10 + str(progress) + '%', end='')\n",
    "            state = 0\n",
    "            player = 0\n",
    "            while self.judge.get_result(state) == 3:\n",
    "                action = self.agents[player].get_action(state)\n",
    "                state += (player + 1) * 3 ** action\n",
    "                player = (player + 1) % 2\n",
    "                state = base_states[state]\n",
    "                \n",
    "            winner = self.judge.get_result(state)\n",
    "            if winner:\n",
    "                self.agents[winner - 1].put_reward(100)\n",
    "                self.agents[1 - (winner - 1)].put_reward(-100)\n",
    "            else:\n",
    "                for agent in self.agents:\n",
    "                    agent.put_reward(1)\n",
    "        #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SARSA_agents = AgentSARSA(alpha=0.05), AgentSARSA(alpha=0.05)\n",
    "\n",
    "sim = Simulator(judge, SARSA_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%Duration:  48.84771599999999\n"
     ]
    }
   ],
   "source": [
    "SARSA_agents[1].epsolon = 0.01\n",
    "\n",
    "import time\n",
    "cl = time.clock()\n",
    "sim.play_games(100000)\n",
    "cl = time.clock() - cl\n",
    "print('Duration: ', cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    def get_action(self, state):\n",
    "        return np.random.choice(allowed_actions[state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StrategiesComparator:\n",
    "    def __init__(self, agents, win_reward, draw_reward):\n",
    "        self.agents = agents\n",
    "        self.win_reward = win_reward\n",
    "        self.draw_reward = draw_reward\n",
    "        self.rewards = np.zeros(2)\n",
    "        \n",
    "    def compare(self, tests):\n",
    "        for i in range(tests):\n",
    "            state = 0\n",
    "            player = 0\n",
    "            while judge.get_result(state) == 3:\n",
    "                action = self.agents[player].get_action(state)\n",
    "                state += (player + 1) * 3 ** action\n",
    "                player = (player + 1) % 2\n",
    "                state = base_states[state]\n",
    "                \n",
    "            winner = judge.get_result(state)\n",
    "            if winner:\n",
    "                self.rewards[winner - 1] += self.win_reward\n",
    "            else:\n",
    "                self.rewards += self.draw_reward\n",
    "        return self.rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99834\n"
     ]
    }
   ],
   "source": [
    "rand_agent = RandomAgent()\n",
    "ag = SARSA_agents[1]\n",
    "ag.epsilon = 0\n",
    "comp = StrategiesComparator([rand_agent, ag], 100, 100)\n",
    "\n",
    "tests = 50000\n",
    "rewards = comp.compare(tests)\n",
    "r = rewards[1]\n",
    "print(r / (100 * tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp.agents[1].epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PlayingInterface:\n",
    "    def __init__(self, agents, role=1):\n",
    "        self.judge = judge\n",
    "        if role == 1:\n",
    "            self.agent = agents[1]\n",
    "        else:\n",
    "            self.agent = agents[0]\n",
    "        self.agent.epsilon = 0\n",
    "        self.agent_role = 3 - role\n",
    "        self.role = role        \n",
    "        \n",
    "    def start(self):\n",
    "        self.agent.state = -1\n",
    "        transform = []\n",
    "        res = 3\n",
    "        state = 0\n",
    "        if self.role == 2:\n",
    "            action = self.agent.get_action(state)\n",
    "            state += self.agent_role * 3 ** action\n",
    "        self.print_board(state)\n",
    "        \n",
    "        while res == 3:\n",
    "            y, x = list(map(int, input().split()))\n",
    "            action = y * 3 + x\n",
    "            state += self.role * 3 ** action\n",
    "            res = self.judge.get_result(state)\n",
    "            \n",
    "            transform = transforms[state]\n",
    "            state = base_states[state]\n",
    "            \n",
    "            if res == 3:\n",
    "                action = self.agent.get_action(state)\n",
    "                state += self.agent_role * 3 ** action\n",
    "                res = self.judge.get_result(state)\n",
    "            \n",
    "            board = int_to_board(state)\n",
    "            board = np.rot90(board, transform[0])\n",
    "            if transform[1]:\n",
    "                board = np.fliplr(board)\n",
    "            state = board_to_int(board)\n",
    "            \n",
    "            self.print_board(state)\n",
    "\n",
    "        if res == self.role:\n",
    "            print(\"You won\")\n",
    "        elif res == self.agent_role:\n",
    "            print(\"You lost\")\n",
    "        elif res == 0:\n",
    "            print(\"Draw\")\n",
    "        \n",
    "        print('Restart? (y/n)')\n",
    "        ans = input()\n",
    "        if ans == 'y':\n",
    "            self.start()\n",
    "        \n",
    "    def print_board(self, state):\n",
    "        b = int_to_board(state)\n",
    "        print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = PlayingInterface(SARSA_agents, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "1 1\n",
      "[[2 0 0]\n",
      " [0 1 0]\n",
      " [0 0 0]]\n",
      "0 1\n",
      "[[2 1 0]\n",
      " [0 1 0]\n",
      " [0 2 0]]\n",
      "1 0\n",
      "[[2 1 0]\n",
      " [1 1 2]\n",
      " [0 2 0]]\n",
      "2 0\n",
      "[[2 1 2]\n",
      " [1 1 2]\n",
      " [1 2 0]]\n",
      "2 2\n",
      "[[2 1 2]\n",
      " [1 1 2]\n",
      " [1 2 1]]\n",
      "Draw\n",
      "Restart? (y/n)\n",
      "n\n"
     ]
    }
   ],
   "source": [
    "p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "81\n",
      "[[0 0 0]\n",
      " [0 1 0]\n",
      " [0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-14.75368773, -21.61311116, -16.46562046, -22.75215832,\n",
       "         0.        , -25.95705198, -18.0340858 , -20.60184509,   2.9912765 ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.zeros((3, 3), 'int')\n",
    "b[1][1] = 1\n",
    "x = board_to_int(b)\n",
    "print(x)\n",
    "print(base_states[x])\n",
    "print(int_to_board(x))\n",
    "SARSA_agents[1].q[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AgentQ(AgentSARSA):\n",
    "    def get_action(self, state):\n",
    "        action = self.choose_action(state)\n",
    "        q_max = self.q[state].take(allowed_actions[state]).max()\n",
    "        \n",
    "        self.q[self.prev_state][self.prev_action] += self.alpha * (self.gamma * q_max\n",
    "                                                                   - self.q[self.prev_state][self.prev_action])\n",
    "        self.prev_state = state\n",
    "        self.prev_action = action\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "Q_agents = [AgentQ(alpha=0.05), AgentQ(alpha=0.05)]\n",
    "\n",
    "sim2 = Simulator(judge, Q_agents)\n",
    "sim2.play_games(100000)\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = PlayingInterface(Q_agents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "1 1\n",
      "[[0 0 2]\n",
      " [0 1 0]\n",
      " [0 0 0]]\n",
      "0 1\n",
      "[[0 1 2]\n",
      " [0 1 0]\n",
      " [0 2 0]]\n",
      "2 2\n",
      "[[2 1 2]\n",
      " [0 1 0]\n",
      " [0 2 1]]\n",
      "1 0\n",
      "[[2 1 2]\n",
      " [1 1 2]\n",
      " [0 2 1]]\n",
      "2 0\n",
      "Draw\n"
     ]
    }
   ],
   "source": [
    "p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
